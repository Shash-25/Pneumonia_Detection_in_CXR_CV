{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec37993-7d02-4995-bc69-7c4ca9b8d673",
   "metadata": {},
   "source": [
    "# Transfer Learning \n",
    "#### Here, we train model to detect pneumonia using transfer learning with the help of MobileNet, Inception, ResNet50, and ResNet152 \n",
    "\n",
    "#### In this notebook, we do the following :-\n",
    "1. Define basic parameters for image processing like image_size and batch_size\n",
    "2. Create a tensorflow data pipeline to efficiently read the images while training the model\n",
    "3. Train preloaded MobileNet model - a) by freezing the CNN parameters, b) by fine-tuning the CNN parameters\n",
    "3. Train preloaded ResNet50 model - a) by freezing the CNN parameters, b) by fine-tuning the CNN parameters\n",
    "4. Train ResNet152 - a) by freezing the CNN parameters (limited computational resource to train all parameters)\n",
    "5. Train InceptionV3 - a) by freezing the CNN parameters, b) by fine-tuning the CNN parameters\n",
    "\n",
    "<i>The performance analysis of all these trained models is done in \"d) Model Performance Analysis\" notebook</i><br>\n",
    "\n",
    "#### Transfer Learning is done such that,\n",
    "1. When the layers are frozen, we apply a fresh trainable Conv2D layer followed by fully connected layers to get the output\n",
    "2. When the layers are trainable, we directly connect them to fresh fully connected layers to get the output\n",
    "\n",
    "#### The data pipeline does the following :-\n",
    "1. Reads a \"batch\" of image file_paths from the metadata\n",
    "2. Read those images and processes it - resizing, casting into appropiate datatype, image_augmentation (only in training)\n",
    "4. Return the batch of processed images for feeding into the model for training or validation\n",
    "5. The data pipeline shuffles the training set while creating a batch to train the model to avoid ordering bias\n",
    "6. It also automatically determines the appropiate #threads while mapping the file path to output image to save time\n",
    "7. It prefetches the next batch while the current batch is feed into the model for training to save time\n",
    "\n",
    "#### Following callback methods were used while training :-\n",
    "1. <b>ReduceLROnPlateau</b> - this will reduce the learning rate by some factor if the monitored metric (val_loss) decreases twice in epochs while training. This will avoid overfitting\n",
    "2. <b>ModelCheckpoint</b> - this saves the model after each epoch. This will allow us to use any intermediate epoch model if needed\n",
    "3. <b>CSVLogger</b> - this saves the model performance metrics after each epoch in a csv file for later analysis\n",
    "4. <b>EarlyStopping</b> - this will stop training of the model if monitored metric (val_loss) decreases 3 times in a row. This will avoid overfitting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5019db6c-1c91-4a51-a80f-2b971c7dd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, GlobalMaxPooling2D, ReLU, GlobalAveragePooling2D, Rescaling\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9e703-0dc9-4186-90f9-099782227fd9",
   "metadata": {},
   "source": [
    "# Parameters for Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bace6957-73b1-4a4a-8a11-3b240db0f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acec0f5-3067-44c6-b6c3-d712c7934a19",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba073b3d-b9d2-4776-a158-022128025394",
   "metadata": {},
   "source": [
    "### Prepare metadata for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea4050a-14f5-4eb2-9593-53d39104d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25727, 12)\n",
      "(2250, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('Data/pneumonia/train_metadata.csv')\n",
    "train_df['file_path'] = 'Data/pneumonia/Training/Images/' + train_df['patientId'] + '.png'\n",
    "train_data = list(zip(train_df['file_path'], train_df['Target']))\n",
    "train_paths, train_target = zip(*train_data)\n",
    "\n",
    "\n",
    "validation_df = pd.read_csv('Data/pneumonia/val_metadata.csv')\n",
    "validation_df['file_path'] = 'Data/pneumonia/Training/Images/' + validation_df['patientId'] + '.png'\n",
    "validation_data = list(zip(validation_df['file_path'], validation_df['Target']))\n",
    "validation_paths, validation_target = zip(*validation_data)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8303f86-df41-43dc-a14f-c0c985d01f42",
   "metadata": {},
   "source": [
    "### Mapping Function for Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb1aaf-3d72-4514-8443-874eaff4824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation block\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n",
    "\n",
    "augmentation_block = tf.keras.Sequential([\n",
    "    RandomFlip(\"vertical\"),\n",
    "], name=\"data_augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c9f8613-caf2-4223-b232-e7d43ce002ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_process_train(image_path, target):\n",
    "\n",
    "    #read file\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    #process image\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE], method = 'bilinear')\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.grayscale_to_rgb(image) #to convert from 1 channels to 3 channels\n",
    "    \n",
    "    #augmentation\n",
    "    image = augmentation_block(image, training=True)\n",
    "    \n",
    "    return image, target\n",
    "\n",
    "def load_and_process_validation(image_path, target):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE], method = 'bilinear')\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.grayscale_to_rgb(image) #to convert from 1 channels to 3 channels\n",
    "\n",
    "    return image, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e51cb7-3110-45c8-86fb-e7e98797a6ed",
   "metadata": {},
   "source": [
    "### Create Tensorflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "254bc574-3740-47ea-88ea-7a66d114add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((list(train_paths), list(train_target)))\n",
    "train_ds = train_ds.map(load_and_process_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(100).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((list(validation_paths),  list(validation_target)))\n",
    "val_ds = val_ds.map(load_and_process_validation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d1b2b-6051-4541-aebf-4c4ea63de127",
   "metadata": {},
   "source": [
    "# Compile and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4f1403-082e-43e0-ba52-785fc297389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_compile_and_fit(model,model_name):\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \\\n",
    "                  loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), AUC(name='auc')])\n",
    "\n",
    "    os.makedirs(f\"final_models/{model_name}\", exist_ok=True)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=2, min_lr=1e-6,verbose=1)\n",
    "    \n",
    "    checkpoint_cb = ModelCheckpoint(filepath=f\"final_models/{model_name}/{model_name}_{{epoch:02d}}.keras\",save_freq='epoch', \\\n",
    "                                    save_weights_only=True,save_best_only=False,verbose=1)\n",
    "    \n",
    "    csv_logger = CSVLogger(f\"final_models//{model_name}/{model_name}_log.csv\", append=True)\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss',patience=3,mode='min', verbose = 1)\n",
    "    \n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=20, verbose = 1, \\\n",
    "            callbacks=[checkpoint_cb, reduce_lr,csv_logger, early_stop])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea22b3-e7c6-4a8a-a0d6-3c373f3c7267",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def5537-8f22-4677-81a3-e01a3c62e92f",
   "metadata": {},
   "source": [
    "### Convolution and Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816d3a05-779d-4c79-ba17-a267e815c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(x):\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x) #512\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b31ee-79a9-463f-917d-82aa00fd5d5a",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2644f810-7d01-4ef2-989a-b933f2ed656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.applications.MobileNet(\n",
    "    input_shape = (224, 224, 3),\n",
    "    include_top = False,\n",
    "    weights = 'imagenet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0591359-f0d7-4ff9-a66c-88f0b941fdd2",
   "metadata": {},
   "source": [
    "### Train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4773427e-93a8-4c0b-9886-eb011816d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.trainable = True\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "rescaled_inputs = Rescaling(scale = 2, offset = -1)(inputs) #taking pixels from [0,1] to [-1,1]\n",
    "mobilenet_x = mobilenet(rescaled_inputs)\n",
    "outputs = fc_layer(mobilenet_x)\n",
    "mobilenet_model = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "366fe13e-0f4e-403c-8d00-69a24f26e3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.7347 - precision: 0.5873 - recall: 0.5554 - auc: 0.7689\n",
      "Epoch 1: saving model to final_models/mobilenet_trainable\\mobilenet_trainable_01.keras\n",
      "2144/2144 [==============================] - 207s 92ms/step - loss: 0.6082 - accuracy: 0.7347 - precision: 0.5873 - recall: 0.5554 - auc: 0.7689 - val_loss: 0.5282 - val_accuracy: 0.7631 - val_precision: 0.7973 - val_recall: 0.3329 - val_auc: 0.8388 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.7911 - precision: 0.6949 - recall: 0.6106 - auc: 0.8499\n",
      "Epoch 2: saving model to final_models/mobilenet_trainable\\mobilenet_trainable_02.keras\n",
      "2144/2144 [==============================] - 190s 89ms/step - loss: 0.4500 - accuracy: 0.7911 - precision: 0.6949 - recall: 0.6106 - auc: 0.8499 - val_loss: 0.4524 - val_accuracy: 0.7844 - val_precision: 0.8294 - val_recall: 0.3977 - val_auc: 0.8623 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8040 - precision: 0.7297 - recall: 0.6087 - auc: 0.8686\n",
      "Epoch 3: saving model to final_models/mobilenet_trainable\\mobilenet_trainable_03.keras\n",
      "2144/2144 [==============================] - 192s 89ms/step - loss: 0.4223 - accuracy: 0.8040 - precision: 0.7297 - recall: 0.6087 - auc: 0.8686 - val_loss: 0.4559 - val_accuracy: 0.7773 - val_precision: 0.8514 - val_recall: 0.3554 - val_auc: 0.8709 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8144 - precision: 0.7738 - recall: 0.5875 - auc: 0.8845\n",
      "Epoch 4: saving model to final_models/mobilenet_trainable\\mobilenet_trainable_04.keras\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 187s 87ms/step - loss: 0.3981 - accuracy: 0.8144 - precision: 0.7738 - recall: 0.5875 - auc: 0.8845 - val_loss: 0.4677 - val_accuracy: 0.7924 - val_precision: 0.7937 - val_recall: 0.4612 - val_auc: 0.8473 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.8408 - precision: 0.8036 - recall: 0.6603 - auc: 0.9100\n",
      "Epoch 5: saving model to final_models/mobilenet_trainable\\mobilenet_trainable_05.keras\n",
      "2144/2144 [==============================] - 186s 87ms/step - loss: 0.3546 - accuracy: 0.8408 - precision: 0.8036 - recall: 0.6603 - auc: 0.9100 - val_loss: 0.4738 - val_accuracy: 0.7680 - val_precision: 0.8304 - val_recall: 0.3315 - val_auc: 0.8339 - lr: 1.0000e-05\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(mobilenet_model, 'mobilenet_trainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da1d5d-0e8c-4c36-847a-cebe64c143f2",
   "metadata": {},
   "source": [
    "### Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318ff863-60d1-4034-abdf-5802bf26f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.trainable = False\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "rescaled_inputs = Rescaling(scale = 2, offset = -1)(inputs)\n",
    "x = mobilenet(rescaled_inputs)\n",
    "x = Conv2D(512, (3,3), padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "outputs = fc_layer(x)\n",
    "mobilenet_model_untrainable = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb06214-58b8-48f7-adb1-549a95f721bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.7264 - precision: 0.5921 - recall: 0.4470 - auc: 0.7393\n",
      "Epoch 1: saving model to final_models/mobilenet_untrainable\\mobilenet_untrainable_01.keras\n",
      "2144/2144 [==============================] - 115s 49ms/step - loss: 0.5693 - accuracy: 0.7264 - precision: 0.5921 - recall: 0.4470 - auc: 0.7393 - val_loss: 0.5874 - val_accuracy: 0.7320 - val_precision: 0.6268 - val_recall: 0.3695 - val_auc: 0.7146 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.7588 - precision: 0.6508 - recall: 0.5196 - auc: 0.7912\n",
      "Epoch 2: saving model to final_models/mobilenet_untrainable\\mobilenet_untrainable_02.keras\n",
      "2144/2144 [==============================] - 102s 47ms/step - loss: 0.5087 - accuracy: 0.7588 - precision: 0.6508 - recall: 0.5196 - auc: 0.7912 - val_loss: 0.5599 - val_accuracy: 0.7347 - val_precision: 0.5989 - val_recall: 0.4781 - val_auc: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2143/2144 [============================>.] - ETA: 0s - loss: 0.4916 - accuracy: 0.7695 - precision: 0.6644 - recall: 0.5552 - auc: 0.8078\n",
      "Epoch 3: saving model to final_models/mobilenet_untrainable\\mobilenet_untrainable_03.keras\n",
      "2144/2144 [==============================] - 101s 47ms/step - loss: 0.4916 - accuracy: 0.7696 - precision: 0.6645 - recall: 0.5552 - auc: 0.8078 - val_loss: 0.5569 - val_accuracy: 0.7316 - val_precision: 0.5926 - val_recall: 0.4739 - val_auc: 0.7513 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4758 - accuracy: 0.7792 - precision: 0.6862 - recall: 0.5621 - auc: 0.8214\n",
      "Epoch 4: saving model to final_models/mobilenet_untrainable\\mobilenet_untrainable_04.keras\n",
      "2144/2144 [==============================] - 101s 47ms/step - loss: 0.4758 - accuracy: 0.7792 - precision: 0.6862 - recall: 0.5621 - auc: 0.8214 - val_loss: 0.5747 - val_accuracy: 0.7164 - val_precision: 0.5603 - val_recall: 0.4654 - val_auc: 0.7304 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.7865 - precision: 0.6943 - recall: 0.5859 - auc: 0.8338\n",
      "Epoch 5: saving model to final_models/mobilenet_untrainable\\mobilenet_untrainable_05.keras\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 101s 47ms/step - loss: 0.4603 - accuracy: 0.7865 - precision: 0.6943 - recall: 0.5859 - auc: 0.8338 - val_loss: 0.5741 - val_accuracy: 0.7093 - val_precision: 0.6180 - val_recall: 0.2031 - val_auc: 0.6894 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.8001 - precision: 0.7216 - recall: 0.6040 - auc: 0.8556\n",
      "Epoch 6: saving model to final_models/mobilenet_untrainable\\mobilenet_untrainable_06.keras\n",
      "2144/2144 [==============================] - 101s 47ms/step - loss: 0.4328 - accuracy: 0.8001 - precision: 0.7216 - recall: 0.6040 - auc: 0.8556 - val_loss: 0.5773 - val_accuracy: 0.7111 - val_precision: 0.6139 - val_recall: 0.2243 - val_auc: 0.6909 - lr: 1.0000e-05\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(mobilenet_model_untrainable, 'mobilenet_untrainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf741e-0f9b-496c-84c5-ed7e4a7dc70b",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89afde5e-436f-4bcd-9383-9976390f1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "resnet50 = tf.keras.applications.ResNet50(\n",
    "    input_shape = (224, 224, 3),\n",
    "    include_top = False, #weather to include the FC layer at the end\n",
    "    weights = 'imagenet') #whather to initialize the weights particular to some dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202331a7-0234-4246-b287-68191d343753",
   "metadata": {},
   "source": [
    "### Train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97099eac-0ea9-46fe-8f2f-4603f4923b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet50.trainable = True\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "scaled_inputs_for_preprocessing = Rescaling(scale = 255)(inputs)\n",
    "preprocessed_inputs = resnet.preprocess_input(scaled_inputs_for_preprocessing)\n",
    "resnet50_x = resnet50(preprocessed_inputs)\n",
    "outputs = fc_layer(resnet50_x)\n",
    "resnet50_model = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a30634-9391-49cd-a958-48d50eab712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.7363 - precision: 0.5933 - recall: 0.5413 - auc: 0.7763\n",
      "Epoch 1: saving model to final_models/resnet50_trainable\\resnet50_trainable_01.keras\n",
      "2144/2144 [==============================] - 589s 268ms/step - loss: 0.6377 - accuracy: 0.7363 - precision: 0.5933 - recall: 0.5413 - auc: 0.7763 - val_loss: 0.4893 - val_accuracy: 0.7560 - val_precision: 0.7516 - val_recall: 0.3371 - val_auc: 0.8356 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.7793 - precision: 0.7157 - recall: 0.5068 - auc: 0.8367\n",
      "Epoch 2: saving model to final_models/resnet50_trainable\\resnet50_trainable_02.keras\n",
      "2144/2144 [==============================] - 571s 266ms/step - loss: 0.4827 - accuracy: 0.7793 - precision: 0.7157 - recall: 0.5068 - auc: 0.8367 - val_loss: 0.6309 - val_accuracy: 0.7138 - val_precision: 0.6012 - val_recall: 0.2722 - val_auc: 0.6399 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4772 - accuracy: 0.7852 - precision: 0.7435 - recall: 0.4947 - auc: 0.8387\n",
      "Epoch 3: saving model to final_models/resnet50_trainable\\resnet50_trainable_03.keras\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 570s 266ms/step - loss: 0.4772 - accuracy: 0.7852 - precision: 0.7435 - recall: 0.4947 - auc: 0.8387 - val_loss: 0.5452 - val_accuracy: 0.7680 - val_precision: 0.6851 - val_recall: 0.4880 - val_auc: 0.8111 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8042 - precision: 0.7937 - recall: 0.5185 - auc: 0.8777\n",
      "Epoch 4: saving model to final_models/resnet50_trainable\\resnet50_trainable_04.keras\n",
      "2144/2144 [==============================] - 574s 267ms/step - loss: 0.4101 - accuracy: 0.8042 - precision: 0.7937 - recall: 0.5185 - auc: 0.8777 - val_loss: 0.5123 - val_accuracy: 0.7596 - val_precision: 0.8231 - val_recall: 0.3018 - val_auc: 0.8247 - lr: 1.0000e-05\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(resnet50_model, 'resnet50_trainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67d51d-b821-458d-bc9a-3655e2532907",
   "metadata": {},
   "source": [
    "### Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09055fb4-f289-4b9e-8bac-cff08644f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.trainable = False\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "scaled_inputs_for_preprocessing = Rescaling(scale = 255)(inputs)\n",
    "preprocessed_inputs = resnet.preprocess_input(scaled_inputs_for_preprocessing)\n",
    "resnet50_x = resnet50(preprocessed_inputs)\n",
    "x = Conv2D(512, (3,3), padding = 'same')(resnet50_x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "outputs = fc_layer(x)\n",
    "resnet50_model_untrainable = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da5b2a59-1cbc-4d50-99b6-ed2762bd124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5651 - accuracy: 0.7100 - precision: 0.5643 - recall: 0.3825 - auc: 0.7246\n",
      "Epoch 1: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_01.keras\n",
      "2144/2144 [==============================] - 275s 124ms/step - loss: 0.5651 - accuracy: 0.7100 - precision: 0.5643 - recall: 0.3825 - auc: 0.7246 - val_loss: 0.6114 - val_accuracy: 0.7476 - val_precision: 0.5949 - val_recall: 0.6234 - val_auc: 0.7939 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.7449 - precision: 0.6316 - recall: 0.4733 - auc: 0.7787\n",
      "Epoch 2: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_02.keras\n",
      "2144/2144 [==============================] - 259s 121ms/step - loss: 0.5180 - accuracy: 0.7449 - precision: 0.6316 - recall: 0.4733 - auc: 0.7787 - val_loss: 0.5687 - val_accuracy: 0.7360 - val_precision: 0.5592 - val_recall: 0.7659 - val_auc: 0.8119 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7555 - precision: 0.6463 - recall: 0.5091 - auc: 0.7955\n",
      "Epoch 3: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_03.keras\n",
      "2144/2144 [==============================] - 258s 120ms/step - loss: 0.5041 - accuracy: 0.7555 - precision: 0.6463 - recall: 0.5091 - auc: 0.7955 - val_loss: 0.5748 - val_accuracy: 0.7191 - val_precision: 0.5371 - val_recall: 0.7856 - val_auc: 0.8068 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.7639 - precision: 0.6607 - recall: 0.5281 - auc: 0.8028\n",
      "Epoch 4: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_04.keras\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 259s 121ms/step - loss: 0.4958 - accuracy: 0.7639 - precision: 0.6607 - recall: 0.5281 - auc: 0.8028 - val_loss: 0.5832 - val_accuracy: 0.7413 - val_precision: 0.5632 - val_recall: 0.7983 - val_auc: 0.8215 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7729 - precision: 0.6691 - recall: 0.5643 - auc: 0.8132\n",
      "Epoch 5: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_05.keras\n",
      "2144/2144 [==============================] - 258s 120ms/step - loss: 0.4849 - accuracy: 0.7729 - precision: 0.6691 - recall: 0.5643 - auc: 0.8132 - val_loss: 0.5593 - val_accuracy: 0.7627 - val_precision: 0.6019 - val_recall: 0.7292 - val_auc: 0.8206 - lr: 1.0000e-05\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.7782 - precision: 0.6727 - recall: 0.5879 - auc: 0.8208\n",
      "Epoch 6: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_06.keras\n",
      "2144/2144 [==============================] - 258s 120ms/step - loss: 0.4765 - accuracy: 0.7782 - precision: 0.6727 - recall: 0.5879 - auc: 0.8208 - val_loss: 0.5606 - val_accuracy: 0.7547 - val_precision: 0.5864 - val_recall: 0.7518 - val_auc: 0.8196 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.7750 - precision: 0.6681 - recall: 0.5803 - auc: 0.8205\n",
      "Epoch 7: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_07.keras\n",
      "2144/2144 [==============================] - 261s 121ms/step - loss: 0.4765 - accuracy: 0.7750 - precision: 0.6681 - recall: 0.5803 - auc: 0.8205 - val_loss: 0.5543 - val_accuracy: 0.7649 - val_precision: 0.6108 - val_recall: 0.6996 - val_auc: 0.8201 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.7758 - precision: 0.6708 - recall: 0.5785 - auc: 0.8240\n",
      "Epoch 8: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_08.keras\n",
      "2144/2144 [==============================] - 260s 121ms/step - loss: 0.4732 - accuracy: 0.7758 - precision: 0.6708 - recall: 0.5785 - auc: 0.8240 - val_loss: 0.5490 - val_accuracy: 0.7742 - val_precision: 0.6290 - val_recall: 0.6911 - val_auc: 0.8203 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.7803 - precision: 0.6797 - recall: 0.5834 - auc: 0.8256\n",
      "Epoch 9: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_09.keras\n",
      "2144/2144 [==============================] - 261s 121ms/step - loss: 0.4714 - accuracy: 0.7803 - precision: 0.6797 - recall: 0.5834 - auc: 0.8256 - val_loss: 0.5571 - val_accuracy: 0.7671 - val_precision: 0.6143 - val_recall: 0.7010 - val_auc: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 10/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.7819 - precision: 0.6836 - recall: 0.5842 - auc: 0.8255\n",
      "Epoch 10: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_10.keras\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "2144/2144 [==============================] - 261s 121ms/step - loss: 0.4712 - accuracy: 0.7819 - precision: 0.6836 - recall: 0.5842 - auc: 0.8255 - val_loss: 0.5563 - val_accuracy: 0.7640 - val_precision: 0.6042 - val_recall: 0.7278 - val_auc: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.7831 - precision: 0.6874 - recall: 0.5824 - auc: 0.8272\n",
      "Epoch 11: saving model to final_models/resnet50_untrainable\\resnet50_untrainable_11.keras\n",
      "2144/2144 [==============================] - 260s 121ms/step - loss: 0.4685 - accuracy: 0.7831 - precision: 0.6874 - recall: 0.5824 - auc: 0.8272 - val_loss: 0.5513 - val_accuracy: 0.7689 - val_precision: 0.6183 - val_recall: 0.6968 - val_auc: 0.8238 - lr: 1.0000e-06\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(resnet50_model_untrainable, 'resnet50_untrainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78731ab4-896a-4bfe-9a3e-5a9637d3fb21",
   "metadata": {},
   "source": [
    "# ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b991bad7-125a-4a38-b0a9-8ee513b25ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "resnet152 = tf.keras.applications.ResNet152(\n",
    "    input_shape = (224, 224, 3),\n",
    "    include_top = False, \n",
    "    weights = 'imagenet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2919e72f-5aff-4c0d-a833-33495af252bf",
   "metadata": {},
   "source": [
    "### Train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8543a800-fdf6-4f02-8a45-9ba78b91e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152.trainable = True\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "scaled_inputs_for_preprocessing = Rescaling(scale = 255)(inputs)\n",
    "preprocessed_inputs = resnet.preprocess_input(scaled_inputs_for_preprocessing)\n",
    "resnet152_x = resnet152(preprocessed_inputs)\n",
    "outputs = fc_layer(resnet152_x)\n",
    "resnet152_model = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2763d-5aaf-4a0e-a12f-77cbe2f3e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compile_and_fit(resnet152_model, 'resnet152_trainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8141a-bd4c-43d4-97d4-b334809ff5f4",
   "metadata": {},
   "source": [
    "### Freeze Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a32d0a4-70fe-4858-8bcb-939ddd163760",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152.trainable = False\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "scaled_inputs_for_preprocessing = Rescaling(scale = 255)(inputs)\n",
    "preprocessed_inputs = resnet.preprocess_input(scaled_inputs_for_preprocessing)\n",
    "resnet152_x = resnet152(preprocessed_inputs)\n",
    "x = Conv2D(512, (3,3), padding = 'same')(resnet152_x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "outputs = fc_layer(x)\n",
    "resnet152_untrainable_model = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68b5312a-dae8-4c05-a1ce-7942fd68cc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7113 - precision: 0.5624 - recall: 0.4122 - auc: 0.7291\n",
      "Epoch 1: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_01.keras\n",
      "2144/2144 [==============================] - 554s 253ms/step - loss: 0.5645 - accuracy: 0.7113 - precision: 0.5624 - recall: 0.4122 - auc: 0.7291 - val_loss: 0.4911 - val_accuracy: 0.7756 - val_precision: 0.6903 - val_recall: 0.5219 - val_auc: 0.8230 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.7447 - precision: 0.6239 - recall: 0.4947 - auc: 0.7809\n",
      "Epoch 2: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_02.keras\n",
      "2144/2144 [==============================] - 535s 250ms/step - loss: 0.5184 - accuracy: 0.7447 - precision: 0.6239 - recall: 0.4947 - auc: 0.7809 - val_loss: 0.4823 - val_accuracy: 0.7862 - val_precision: 0.6686 - val_recall: 0.6375 - val_auc: 0.8303 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.7589 - precision: 0.6496 - recall: 0.5234 - auc: 0.7965\n",
      "Epoch 3: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_03.keras\n",
      "2144/2144 [==============================] - 533s 249ms/step - loss: 0.5030 - accuracy: 0.7589 - precision: 0.6496 - recall: 0.5234 - auc: 0.7965 - val_loss: 0.4788 - val_accuracy: 0.7662 - val_precision: 0.7764 - val_recall: 0.3625 - val_auc: 0.8329 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4997 - accuracy: 0.7599 - precision: 0.6461 - recall: 0.5408 - auc: 0.7993\n",
      "Epoch 4: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_04.keras\n",
      "2144/2144 [==============================] - 537s 250ms/step - loss: 0.4997 - accuracy: 0.7599 - precision: 0.6461 - recall: 0.5408 - auc: 0.7993 - val_loss: 0.5021 - val_accuracy: 0.7769 - val_precision: 0.6332 - val_recall: 0.6939 - val_auc: 0.8340 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4910 - accuracy: 0.7705 - precision: 0.6628 - recall: 0.5655 - auc: 0.8080\n",
      "Epoch 5: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_05.keras\n",
      "2144/2144 [==============================] - 536s 250ms/step - loss: 0.4910 - accuracy: 0.7705 - precision: 0.6628 - recall: 0.5655 - auc: 0.8080 - val_loss: 0.4755 - val_accuracy: 0.7893 - val_precision: 0.6929 - val_recall: 0.5952 - val_auc: 0.8394 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.7691 - precision: 0.6606 - recall: 0.5623 - auc: 0.8100\n",
      "Epoch 6: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_06.keras\n",
      "2144/2144 [==============================] - 535s 250ms/step - loss: 0.4878 - accuracy: 0.7691 - precision: 0.6606 - recall: 0.5623 - auc: 0.8100 - val_loss: 0.4822 - val_accuracy: 0.7867 - val_precision: 0.6579 - val_recall: 0.6728 - val_auc: 0.8433 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.7736 - precision: 0.6704 - recall: 0.5657 - auc: 0.8168\n",
      "Epoch 7: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_07.keras\n",
      "2144/2144 [==============================] - 536s 250ms/step - loss: 0.4809 - accuracy: 0.7736 - precision: 0.6704 - recall: 0.5657 - auc: 0.8168 - val_loss: 0.4684 - val_accuracy: 0.7924 - val_precision: 0.6704 - val_recall: 0.6714 - val_auc: 0.8481 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.7752 - precision: 0.6699 - recall: 0.5769 - auc: 0.8197\n",
      "Epoch 8: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_08.keras\n",
      "2144/2144 [==============================] - 534s 249ms/step - loss: 0.4776 - accuracy: 0.7752 - precision: 0.6699 - recall: 0.5769 - auc: 0.8197 - val_loss: 0.4635 - val_accuracy: 0.7956 - val_precision: 0.6954 - val_recall: 0.6248 - val_auc: 0.8497 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.7790 - precision: 0.6792 - recall: 0.5770 - auc: 0.8224\n",
      "Epoch 9: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_09.keras\n",
      "2144/2144 [==============================] - 536s 250ms/step - loss: 0.4746 - accuracy: 0.7790 - precision: 0.6792 - recall: 0.5770 - auc: 0.8224 - val_loss: 0.4562 - val_accuracy: 0.7902 - val_precision: 0.7651 - val_recall: 0.4824 - val_auc: 0.8488 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.7816 - precision: 0.6827 - recall: 0.5841 - auc: 0.8243\n",
      "Epoch 10: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_10.keras\n",
      "2144/2144 [==============================] - 536s 250ms/step - loss: 0.4723 - accuracy: 0.7816 - precision: 0.6827 - recall: 0.5841 - auc: 0.8243 - val_loss: 0.4506 - val_accuracy: 0.7973 - val_precision: 0.7271 - val_recall: 0.5712 - val_auc: 0.8509 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.7790 - precision: 0.6754 - recall: 0.5865 - auc: 0.8253\n",
      "Epoch 11: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_11.keras\n",
      "2144/2144 [==============================] - 535s 250ms/step - loss: 0.4702 - accuracy: 0.7790 - precision: 0.6754 - recall: 0.5865 - auc: 0.8253 - val_loss: 0.4704 - val_accuracy: 0.7884 - val_precision: 0.6499 - val_recall: 0.7123 - val_auc: 0.8506 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7819 - precision: 0.6817 - recall: 0.5883 - auc: 0.8297\n",
      "Epoch 12: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_12.keras\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 536s 250ms/step - loss: 0.4659 - accuracy: 0.7819 - precision: 0.6817 - recall: 0.5883 - auc: 0.8297 - val_loss: 0.4531 - val_accuracy: 0.8013 - val_precision: 0.7205 - val_recall: 0.6037 - val_auc: 0.8540 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.7859 - precision: 0.6869 - recall: 0.5993 - auc: 0.8343\n",
      "Epoch 13: saving model to final_models/resnet152_untrainable_model\\resnet152_untrainable_model_13.keras\n",
      "2144/2144 [==============================] - 536s 250ms/step - loss: 0.4607 - accuracy: 0.7859 - precision: 0.6869 - recall: 0.5993 - auc: 0.8343 - val_loss: 0.4561 - val_accuracy: 0.8009 - val_precision: 0.6945 - val_recall: 0.6573 - val_auc: 0.8543 - lr: 1.0000e-05\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(resnet152_untrainable_model, 'resnet152_untrainable_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4dbf89-2595-491a-8d76-316d7cda777e",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2625735-6fa1-4044-94f6-3c76f5e1adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inceptionv3 = tf.keras.applications.InceptionV3(\n",
    "    input_shape = (IMG_SIZE, IMG_SIZE, 3), #299\n",
    "    include_top = False,\n",
    "    weights = 'imagenet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04a106-1980-4071-bc8c-dd7d81219ac9",
   "metadata": {},
   "source": [
    "### Train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994e6255-2b10-4c91-8266-7120df1ec49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inceptionv3.trainable = True\n",
    "\n",
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "rescaled_inputs = Rescaling(scale = 2, offset = -1)(inputs)\n",
    "inceptionv3_x = inceptionv3(rescaled_inputs)\n",
    "outputs = fc_layer(inceptionv3_x)\n",
    "inceptionv3_model = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8c42e9-252c-47b5-811d-126d42d3eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.7812 - precision: 0.6766 - recall: 0.5966 - auc: 0.8335\n",
      "Epoch 1: saving model to final_models/inceptionv3_trainable\\inceptionv3_trainable_01.keras\n",
      "2144/2144 [==============================] - 779s 354ms/step - loss: 0.4727 - accuracy: 0.7812 - precision: 0.6766 - recall: 0.5966 - auc: 0.8335 - val_loss: 0.5319 - val_accuracy: 0.8067 - val_precision: 0.7276 - val_recall: 0.6178 - val_auc: 0.8710 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8209 - precision: 0.7410 - recall: 0.6709 - auc: 0.8812\n",
      "Epoch 2: saving model to final_models/inceptionv3_trainable\\inceptionv3_trainable_02.keras\n",
      "2144/2144 [==============================] - 759s 354ms/step - loss: 0.4050 - accuracy: 0.8209 - precision: 0.7410 - recall: 0.6709 - auc: 0.8812 - val_loss: 0.5236 - val_accuracy: 0.7538 - val_precision: 0.8355 - val_recall: 0.2722 - val_auc: 0.8619 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8396 - precision: 0.7773 - recall: 0.6942 - auc: 0.9003\n",
      "Epoch 3: saving model to final_models/inceptionv3_trainable\\inceptionv3_trainable_03.keras\n",
      "2144/2144 [==============================] - 764s 356ms/step - loss: 0.3725 - accuracy: 0.8396 - precision: 0.7773 - recall: 0.6942 - auc: 0.9003 - val_loss: 0.4528 - val_accuracy: 0.7493 - val_precision: 0.8796 - val_recall: 0.2370 - val_auc: 0.8769 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8627 - precision: 0.8061 - recall: 0.7479 - auc: 0.9235\n",
      "Epoch 4: saving model to final_models/inceptionv3_trainable\\inceptionv3_trainable_04.keras\n",
      "2144/2144 [==============================] - 755s 352ms/step - loss: 0.3282 - accuracy: 0.8627 - precision: 0.8061 - recall: 0.7479 - auc: 0.9235 - val_loss: 0.5575 - val_accuracy: 0.7684 - val_precision: 0.6260 - val_recall: 0.6587 - val_auc: 0.8153 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.8923 - precision: 0.8420 - recall: 0.8138 - auc: 0.9507\n",
      "Epoch 5: saving model to final_models/inceptionv3_trainable\\inceptionv3_trainable_05.keras\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 765s 357ms/step - loss: 0.2647 - accuracy: 0.8923 - precision: 0.8420 - recall: 0.8138 - auc: 0.9507 - val_loss: 0.5741 - val_accuracy: 0.7156 - val_precision: 0.5950 - val_recall: 0.3047 - val_auc: 0.7468 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9466 - precision: 0.9267 - recall: 0.9035 - auc: 0.9856\n",
      "Epoch 6: saving model to final_models/inceptionv3_trainable\\inceptionv3_trainable_06.keras\n",
      "2144/2144 [==============================] - 758s 353ms/step - loss: 0.1415 - accuracy: 0.9466 - precision: 0.9267 - recall: 0.9035 - auc: 0.9856 - val_loss: 0.5381 - val_accuracy: 0.7418 - val_precision: 0.6362 - val_recall: 0.4217 - val_auc: 0.7721 - lr: 1.0000e-05\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(inceptionv3_model, 'inceptionv3_trainable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c26832-6125-4b1b-95ca-6047812a6a7e",
   "metadata": {},
   "source": [
    "### Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c2b4e68-530f-42f8-87cb-40401d6e9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3.trainable = False\n",
    "\n",
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "rescaled_inputs = Rescaling(scale = 2, offset = -1)(inputs)\n",
    "inceptionv3_x = inceptionv3(rescaled_inputs)\n",
    "x = Conv2D(512, (3,3), padding = 'same')(inceptionv3_x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "outputs = fc_layer(x)\n",
    "inceptionv3_model_untrainable = Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd14f7d-484f-468f-b9cd-3530f568d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.7406 - precision: 0.6196 - recall: 0.4760 - auc: 0.7717\n",
      "Epoch 1: saving model to final_models/inceptionv3_model_untrainable\\inceptionv3_model_untrainable_01.keras\n",
      "2144/2144 [==============================] - 323s 145ms/step - loss: 0.5352 - accuracy: 0.7406 - precision: 0.6196 - recall: 0.4760 - auc: 0.7717 - val_loss: 0.5838 - val_accuracy: 0.7440 - val_precision: 0.5874 - val_recall: 0.6305 - val_auc: 0.7924 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7646 - precision: 0.6650 - recall: 0.5222 - auc: 0.8088\n",
      "Epoch 2: saving model to final_models/inceptionv3_model_untrainable\\inceptionv3_model_untrainable_02.keras\n",
      "2144/2144 [==============================] - 306s 142ms/step - loss: 0.4905 - accuracy: 0.7646 - precision: 0.6650 - recall: 0.5222 - auc: 0.8088 - val_loss: 0.5834 - val_accuracy: 0.7493 - val_precision: 0.5989 - val_recall: 0.6192 - val_auc: 0.7978 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.7761 - precision: 0.6828 - recall: 0.5519 - auc: 0.8156\n",
      "Epoch 3: saving model to final_models/inceptionv3_model_untrainable\\inceptionv3_model_untrainable_03.keras\n",
      "2144/2144 [==============================] - 307s 143ms/step - loss: 0.4836 - accuracy: 0.7761 - precision: 0.6828 - recall: 0.5519 - auc: 0.8156 - val_loss: 0.5645 - val_accuracy: 0.7298 - val_precision: 0.7265 - val_recall: 0.2285 - val_auc: 0.7795 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.7789 - precision: 0.6859 - recall: 0.5613 - auc: 0.8245\n",
      "Epoch 4: saving model to final_models/inceptionv3_model_untrainable\\inceptionv3_model_untrainable_04.keras\n",
      "2144/2144 [==============================] - 308s 143ms/step - loss: 0.4728 - accuracy: 0.7789 - precision: 0.6859 - recall: 0.5613 - auc: 0.8245 - val_loss: 0.5703 - val_accuracy: 0.7400 - val_precision: 0.6512 - val_recall: 0.3766 - val_auc: 0.7705 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.7822 - precision: 0.6921 - recall: 0.5665 - auc: 0.8296\n",
      "Epoch 5: saving model to final_models/inceptionv3_model_untrainable\\inceptionv3_model_untrainable_05.keras\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2144/2144 [==============================] - 307s 143ms/step - loss: 0.4671 - accuracy: 0.7822 - precision: 0.6921 - recall: 0.5665 - auc: 0.8296 - val_loss: 0.5911 - val_accuracy: 0.7196 - val_precision: 0.6757 - val_recall: 0.2116 - val_auc: 0.7319 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2144/2144 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7903 - precision: 0.7058 - recall: 0.5829 - auc: 0.8399\n",
      "Epoch 6: saving model to final_models/inceptionv3_model_untrainable\\inceptionv3_model_untrainable_06.keras\n",
      "2144/2144 [==============================] - 308s 143ms/step - loss: 0.4543 - accuracy: 0.7903 - precision: 0.7058 - recall: 0.5829 - auc: 0.8399 - val_loss: 0.5860 - val_accuracy: 0.7129 - val_precision: 0.6864 - val_recall: 0.1636 - val_auc: 0.6936 - lr: 1.0000e-05\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_compile_and_fit(inceptionv3_model_untrainable, 'inceptionv3_model_untrainable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db67d81-f689-453c-a65a-184250ad1f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF GPU)",
   "language": "python",
   "name": "tf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
